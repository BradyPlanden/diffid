{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 7: Parallel Optimisation\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand which optimisers support parallelism\n",
    "- Configure population-based optimisers for parallel execution\n",
    "- Benchmark scaling performance\n",
    "- Identify performance bottlenecks\n",
    "- Apply best practices for thread-safe optimisation\n",
    "\n",
    "**Prerequisites:** Tutorials 1-2, basic understanding of parallelism\n",
    "\n",
    "**Runtime:** ~10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Modern CPUs have multiple cores, but not all optimisation algorithms can exploit them. Chronopt provides **automatic parallelisation** for population-based algorithms:\n",
    "\n",
    "### Parallel Optimisers\n",
    "- **CMA-ES**: Population-based evolutionary strategy\n",
    "- **Dynamic Nested Sampling**: Population of live points\n",
    "\n",
    "### Sequential Optimisers  \n",
    "- **Nelder-Mead**: Sequential simplex updates\n",
    "- **Adam**: Sequential gradient steps\n",
    "\n",
    "This tutorial demonstrates how to configure parallelism and measure its impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Import plotting utilities\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import chronopt as chron\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\".\")\n",
    "from utils import setup_plotting\n",
    "\n",
    "setup_plotting()\n",
    "\n",
    "# Detect available cores\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "print(f\"Available CPU cores: {n_cores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Problem: Expensive Rosenbrock\n",
    "\n",
    "To see the benefits of parallelism, we need an **expensive** objective function. Let's add artificial computation time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expensive_rosenbrock(x, delay_ms=10):\n",
    "    \"\"\"\n",
    "    Rosenbrock function with artificial delay to simulate expensive computation.\n",
    "\n",
    "    In real applications, this might be:\n",
    "    - Complex ODE simulation\n",
    "    - Finite element analysis\n",
    "    - Machine learning model evaluation\n",
    "    - Database query\n",
    "    \"\"\"\n",
    "    # Simulate expensive computation\n",
    "    time.sleep(delay_ms / 1000.0)\n",
    "\n",
    "    # Standard Rosenbrock\n",
    "    value = (1 - x[0]) ** 2 + 100 * (x[1] - x[0] ** 2) ** 2\n",
    "    return np.array([value], dtype=float)\n",
    "\n",
    "\n",
    "# Test single evaluation\n",
    "start = time.time()\n",
    "result = expensive_rosenbrock([0.5, 0.5], delay_ms=50)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Single evaluation time: {elapsed:.3f}s\")\n",
    "print(f\"Objective value: {result[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Baseline: Nelder-Mead\n",
    "\n",
    "First, establish a baseline with sequential Nelder-Mead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build problem\n",
    "problem = (\n",
    "    chron.ScalarBuilder()\n",
    "    .with_callable(lambda x: expensive_rosenbrock(x, delay_ms=10))\n",
    "    .with_parameter(\"x\", 1.0)\n",
    "    .with_parameter(\"y\", 1.0)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Sequential Nelder-Mead\n",
    "print(\"Running Nelder-Mead (sequential)...\")\n",
    "start = time.time()\n",
    "\n",
    "result_nm = chron.NelderMead().with_max_iter(100).run(problem, [0.0, 0.0])\n",
    "\n",
    "time_nm = time.time() - start\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NELDER-MEAD (Sequential)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Solution:      {result_nm.x}\")\n",
    "print(f\"Value:         {result_nm.value:.3e}\")\n",
    "print(f\"Evaluations:   {result_nm.evaluations}\")\n",
    "print(f\"Time:          {time_nm:.2f}s\")\n",
    "print(f\"Time per eval: {time_nm / result_nm.evaluations:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Optimisation: CMA-ES\n",
    "\n",
    "CMA-ES evaluates a **population** of candidate solutions each generation. Chronopt automatically parallelises these evaluations across available cores.\n",
    "\n",
    "### Key Parameters:\n",
    "- `population_size`: Number of candidates per generation (default: automatic based on dimension)\n",
    "- More candidates = more parallelism opportunity\n",
    "- Trade-off: larger populations need more generations to converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMA-ES with automatic population size\n",
    "print(\"Running CMA-ES (parallel, default population)...\")\n",
    "start = time.time()\n",
    "\n",
    "result_cmaes_default = (\n",
    "    chron.CMAES().with_max_iter(50).with_step_size(0.5).run(problem, [0.0, 0.0])\n",
    ")\n",
    "\n",
    "time_cmaes_default = time.time() - start\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CMA-ES (Parallel, Default Population)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Solution:      {result_cmaes_default.x}\")\n",
    "print(f\"Value:         {result_cmaes_default.value:.3e}\")\n",
    "print(f\"Evaluations:   {result_cmaes_default.evaluations}\")\n",
    "print(f\"Time:          {time_cmaes_default:.2f}s\")\n",
    "print(f\"Time per eval: {time_cmaes_default / result_cmaes_default.evaluations:.3f}s\")\n",
    "print(f\"\\nSpeedup vs Nelder-Mead: {time_nm / time_cmaes_default:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMA-ES with larger population for more parallelism\n",
    "print(\"Running CMA-ES (parallel, large population)...\")\n",
    "start = time.time()\n",
    "\n",
    "result_cmaes_large = (\n",
    "    chron.CMAES()\n",
    "    .with_max_iter(30)\n",
    "    .with_step_size(0.5)\n",
    "    .with_population_size(20)  # Larger population = more parallel work\n",
    "    .run(problem, [0.0, 0.0])\n",
    ")\n",
    "\n",
    "time_cmaes_large = time.time() - start\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CMA-ES (Parallel, Large Population)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Solution:      {result_cmaes_large.x}\")\n",
    "print(f\"Value:         {result_cmaes_large.value:.3e}\")\n",
    "print(f\"Evaluations:   {result_cmaes_large.evaluations}\")\n",
    "print(f\"Time:          {time_cmaes_large:.2f}s\")\n",
    "print(f\"Time per eval: {time_cmaes_large / result_cmaes_large.evaluations:.3f}s\")\n",
    "print(f\"\\nSpeedup vs Nelder-Mead: {time_nm / time_cmaes_large:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Analysis\n",
    "\n",
    "Let's systematically test how performance scales with:\n",
    "1. **Population size** (parallelism opportunity)\n",
    "2. **Evaluation cost** (compute vs overhead trade-off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different population sizes\n",
    "population_sizes = [4, 8, 12, 16, 20]\n",
    "results_pop = []\n",
    "\n",
    "print(\"Testing different population sizes...\")\n",
    "print(\"(This may take a few minutes)\\n\")\n",
    "\n",
    "for pop_size in population_sizes:\n",
    "    # Adjust iterations to keep total evaluations similar\n",
    "    n_iter = 200 // pop_size\n",
    "\n",
    "    start = time.time()\n",
    "    result = (\n",
    "        chron.CMAES()\n",
    "        .with_max_iter(n_iter)\n",
    "        .with_step_size(0.5)\n",
    "        .with_population_size(pop_size)\n",
    "        .run(problem, [0.0, 0.0])\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    results_pop.append(\n",
    "        {\n",
    "            \"population\": pop_size,\n",
    "            \"time\": elapsed,\n",
    "            \"evaluations\": result.evaluations,\n",
    "            \"time_per_eval\": elapsed / result.evaluations,\n",
    "            \"success\": result.success,\n",
    "            \"value\": result.value,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Pop={pop_size:2d}: {elapsed:6.2f}s, {result.evaluations:4d} evals, \"\n",
    "        f\"{elapsed / result.evaluations:.3f}s/eval\"\n",
    "    )\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scaling\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "pops = [r[\"population\"] for r in results_pop]\n",
    "times = [r[\"time\"] for r in results_pop]\n",
    "time_per_eval = [r[\"time_per_eval\"] for r in results_pop]\n",
    "\n",
    "# Total time vs population size\n",
    "ax1.plot(pops, times, \"o-\", linewidth=2, markersize=10, color=\"#1f77b4\")\n",
    "ax1.set_xlabel(\"Population Size\", fontsize=12)\n",
    "ax1.set_ylabel(\"Total Time (s)\", fontsize=12)\n",
    "ax1.set_title(\"Optimisation Time vs Population Size\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xticks(pops)\n",
    "\n",
    "# Time per evaluation (measures parallelism efficiency)\n",
    "ax2.plot(pops, time_per_eval, \"s-\", linewidth=2, markersize=10, color=\"#ff7f0e\")\n",
    "ax2.axhline(\n",
    "    y=0.01, color=\"red\", linestyle=\"--\", label=\"Sequential baseline (10ms)\", alpha=0.7\n",
    ")\n",
    "ax2.set_xlabel(\"Population Size\", fontsize=12)\n",
    "ax2.set_ylabel(\"Time per Evaluation (s)\", fontsize=12)\n",
    "ax2.set_title(\"Parallelism Efficiency\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xticks(pops)\n",
    "ax2.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "print(\"  - Time per eval < sequential baseline = good parallelism\")\n",
    "print(\"  - Larger populations amortise overhead across more work\")\n",
    "print(\"  - Diminishing returns when population > number of cores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Evaluation Cost\n",
    "\n",
    "Parallelism overhead (thread creation, synchronisation) matters less when evaluations are expensive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different evaluation costs\n",
    "delays_ms = [1, 5, 10, 20, 50]\n",
    "results_cost = []\n",
    "\n",
    "print(\"Testing different evaluation costs...\\n\")\n",
    "\n",
    "for delay in delays_ms:\n",
    "    # Create problem with specific delay\n",
    "    problem_delayed = (\n",
    "        chron.ScalarBuilder()\n",
    "        .with_callable(lambda x, d=delay: expensive_rosenbrock(x, delay_ms=d))\n",
    "        .with_parameter(\"x\", 1.0)\n",
    "        .with_parameter(\"y\", 1.0)\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    # Sequential Nelder-Mead\n",
    "    start = time.time()\n",
    "    result_seq = chron.NelderMead().with_max_iter(50).run(problem_delayed, [0.0, 0.0])\n",
    "    time_seq = time.time() - start\n",
    "\n",
    "    # Parallel CMA-ES\n",
    "    start = time.time()\n",
    "    result_par = (\n",
    "        chron.CMAES()\n",
    "        .with_max_iter(25)\n",
    "        .with_step_size(0.5)\n",
    "        .with_population_size(12)\n",
    "        .run(problem_delayed, [0.0, 0.0])\n",
    "    )\n",
    "    time_par = time.time() - start\n",
    "\n",
    "    speedup = time_seq / time_par\n",
    "\n",
    "    results_cost.append(\n",
    "        {\n",
    "            \"delay_ms\": delay,\n",
    "            \"time_seq\": time_seq,\n",
    "            \"time_par\": time_par,\n",
    "            \"speedup\": speedup,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Delay={delay:3d}ms: Sequential={time_seq:6.2f}s, Parallel={time_par:6.2f}s, \"\n",
    "        f\"Speedup={speedup:.2f}x\"\n",
    "    )\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize speedup vs evaluation cost\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "delays = [r[\"delay_ms\"] for r in results_cost]\n",
    "speedups = [r[\"speedup\"] for r in results_cost]\n",
    "\n",
    "ax.plot(\n",
    "    delays,\n",
    "    speedups,\n",
    "    \"o-\",\n",
    "    linewidth=2.5,\n",
    "    markersize=12,\n",
    "    color=\"#2ca02c\",\n",
    "    markeredgecolor=\"black\",\n",
    "    markeredgewidth=1.5,\n",
    ")\n",
    "ax.axhline(\n",
    "    y=1.0, color=\"red\", linestyle=\"--\", label=\"No speedup\", alpha=0.7, linewidth=2\n",
    ")\n",
    "ax.axhline(\n",
    "    y=n_cores,\n",
    "    color=\"blue\",\n",
    "    linestyle=\":\",\n",
    "    label=f\"Ideal ({n_cores} cores)\",\n",
    "    alpha=0.7,\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Evaluation Cost (ms)\", fontsize=13)\n",
    "ax.set_ylabel(\"Speedup (CMA-ES / Nelder-Mead)\", fontsize=13)\n",
    "ax.set_title(\"Parallel Speedup vs Evaluation Cost\", fontsize=15, fontweight=\"bold\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.grid(True, alpha=0.3, which=\"both\")\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "# Add value labels\n",
    "for delay, speedup in zip(delays, speedups):\n",
    "    ax.annotate(\n",
    "        f\"{speedup:.1f}x\",\n",
    "        xy=(delay, speedup),\n",
    "        xytext=(0, 10),\n",
    "        textcoords=\"offset points\",\n",
    "        ha=\"center\",\n",
    "        fontsize=10,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "print(\"   Parallelism speedup increases with evaluation cost!\")\n",
    "print(\"   Expensive evaluations ‚Üí parallelisation overhead becomes negligible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread Safety Considerations\n",
    "\n",
    "When using parallel optimisation, your **objective function must be thread-safe**:\n",
    "\n",
    "### ‚úÖ Thread-Safe Patterns\n",
    "```python\n",
    "# Pure functions (no shared state)\n",
    "def objective(x):\n",
    "    return np.sum(x**2)\n",
    "\n",
    "# Immutable data structures\n",
    "DATA = np.array([...])\n",
    "def objective(x):\n",
    "    return np.sum((x - DATA)**2)\n",
    "\n",
    "# Read-only global state\n",
    "MODEL_PARAMS = {...}\n",
    "def objective(x):\n",
    "    return simulate(x, MODEL_PARAMS)\n",
    "```\n",
    "\n",
    "### ‚ùå Not Thread-Safe\n",
    "```python\n",
    "# Shared mutable state\n",
    "counter = 0\n",
    "def objective(x):\n",
    "    global counter\n",
    "    counter += 1  # Race condition!\n",
    "    return np.sum(x**2)\n",
    "\n",
    "# Writing to files without locks\n",
    "def objective(x):\n",
    "    with open('log.txt', 'a') as f:  # Multiple threads writing!\n",
    "        f.write(f'{x}\\n')\n",
    "    return np.sum(x**2)\n",
    "```\n",
    "\n",
    "### Solutions for Non-Thread-Safe Code\n",
    "\n",
    "1. **Use locks** (but this reduces parallelism):\n",
    "```python\n",
    "from threading import Lock\n",
    "lock = Lock()\n",
    "\n",
    "def objective(x):\n",
    "    with lock:\n",
    "        # Critical section\n",
    "        return result\n",
    "```\n",
    "\n",
    "2. **Disable parallelism** for problematic code (future feature)\n",
    "\n",
    "3. **Refactor** to eliminate shared state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### When to Use Parallel Optimisation\n",
    "\n",
    "**‚úÖ Parallelism is beneficial when:**\n",
    "- Objective function is expensive (>10ms per evaluation)\n",
    "- Problem has >3 parameters (larger populations useful)\n",
    "- Multiple cores available\n",
    "- Function is thread-safe\n",
    "- Global search needed (CMA-ES vs Nelder-Mead)\n",
    "\n",
    "**‚ùå Parallelism may not help when:**\n",
    "- Function is very fast (<1ms)\n",
    "- Low-dimensional problems (1-2 parameters)\n",
    "- Limited cores available\n",
    "- Thread-safety issues\n",
    "- Sequential algorithms required (Nelder-Mead, Adam)\n",
    "\n",
    "### Tuning for Parallel Performance\n",
    "\n",
    "1. **Match population to cores**: `population_size ‚âà 2 √ó n_cores` often works well\n",
    "2. **Balance iterations**: Fewer iterations with larger population\n",
    "3. **Profile first**: Measure single evaluation time\n",
    "4. **Monitor efficiency**: Check if speedup scales with cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Summary\n",
    "\n",
    "Let's create a summary comparing all approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary comparison\n",
    "summary_data = [\n",
    "    (\"Nelder-Mead (Sequential)\", time_nm, result_nm.evaluations, 1.0),\n",
    "    (\n",
    "        \"CMA-ES (Default Pop)\",\n",
    "        time_cmaes_default,\n",
    "        result_cmaes_default.evaluations,\n",
    "        time_nm / time_cmaes_default,\n",
    "    ),\n",
    "    (\n",
    "        \"CMA-ES (Large Pop)\",\n",
    "        time_cmaes_large,\n",
    "        result_cmaes_large.evaluations,\n",
    "        time_nm / time_cmaes_large,\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Method':<30} {'Time (s)':<12} {'Evals':<10} {'Speedup'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for method, t, evals, speedup in summary_data:\n",
    "    print(f\"{method:<30} {t:<12.2f} {evals:<10} {speedup:.2f}x\")\n",
    "\n",
    "print(\"\\nüí° Key Findings:\")\n",
    "print(f\"   - Best speedup: {max(s for _, _, _, s in summary_data):.2f}x\")\n",
    "print(f\"   - System cores: {n_cores}\")\n",
    "print(\n",
    "    f\"   - Parallel efficiency: {(max(s for _, _, _, s in summary_data) / n_cores * 100):.0f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **CMA-ES automatically parallelises** population evaluations across CPU cores\n",
    "2. **Speedup increases** with evaluation cost (overhead becomes negligible)\n",
    "3. **Population size** controls parallel work per generation\n",
    "4. **Thread safety** is critical - use pure functions or locks\n",
    "5. **Best for expensive functions** (>10ms per evaluation)\n",
    "6. **Monitor efficiency** - speedup should approach number of cores\n",
    "7. **Trade-offs exist** - larger populations need more generations\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- [Tutorial 8: Advanced Cost Functions](08_advanced_cost_functions.ipynb) - Custom objective functions\n",
    "- [Guide: Parallel Execution](../../guides/parallel-execution.md) - Detailed thread safety patterns\n",
    "- [Guide: Tuning Optimisers](../../guides/tuning-optimizers.md) - Population size selection\n",
    "- [API Reference: CMA-ES](../../api-reference/python/optimizers.md#cmaes) - Complete API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Optimal Population**: Find the population size that minimises total time for your hardware\n",
    "\n",
    "2. **Amdahl's Law**: Estimate the theoretical speedup limit based on your results\n",
    "\n",
    "3. **Real Problem**: Apply parallel CMA-ES to an ODE fitting problem from Tutorial 2\n",
    "\n",
    "4. **Scaling Study**: Measure how speedup changes with:\n",
    "   - Number of parameters (2, 5, 10, 20)\n",
    "   - Evaluation cost (1ms, 10ms, 100ms, 1s)\n",
    "   - System load (run with background tasks)\n",
    "\n",
    "5. **Thread Safety Bug**: Create a non-thread-safe objective function and observe the failure mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
