{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Parameter Uncertainty\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Go from optimization to uncertainty quantification\n",
    "- Use MCMC sampling to explore parameter distributions\n",
    "- Interpret MCMC diagnostics and traces\n",
    "- Calculate confidence intervals\n",
    "\n",
    "**Prerequisites:** Tutorials 1-2, basic Bayesian statistics\n",
    "\n",
    "**Runtime:** ~15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Optimization gives us a **single best** parameter estimate. But how **certain** are we about these values?\n",
    "\n",
    "MCMC (Markov Chain Monte Carlo) sampling explores the full **posterior distribution**, letting us:\n",
    "- Quantify parameter uncertainty\n",
    "- Calculate confidence intervals\n",
    "- Detect parameter correlations\n",
    "- Make probabilistic predictions\n",
    "\n",
    "We'll use a bouncy ball physics model as our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting utilities\n",
    "import sys\n",
    "\n",
    "import chronopt as chron\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\".\")\n",
    "from utils import plot_parameter_distributions, plot_parameter_traces, setup_plotting\n",
    "\n",
    "setup_plotting()\n",
    "np.random.seed(42)  # For reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Physics Problem: Falling Ball\n",
    "\n",
    "A ball falls from height $h$ with gravitational acceleration $g$:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\frac{dx}{dt} &= v \\\\\n",
    "\\frac{dv}{dt} &= -g\n",
    "\\end{aligned}$$\n",
    "\n",
    "where:\n",
    "- $x$ is height\n",
    "- $v$ is velocity  \n",
    "- $g$ is gravitational acceleration (Earth: ~9.81 m/s²)\n",
    "- $h$ is initial height\n",
    "\n",
    "**Task**: Estimate $g$ and $h$ from noisy observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ball_states(t, g, h):\n",
    "    \"\"\"Analytical solution for ball trajectory.\"\"\"\n",
    "    height = h - 0.5 * g * t**2\n",
    "    height = np.maximum(height, 0.0)  # Can't go below ground\n",
    "    velocity = -g * t\n",
    "    return height, velocity\n",
    "\n",
    "\n",
    "# True parameters\n",
    "g_true = 9.81  # m/s²\n",
    "h_true = 10.0  # meters\n",
    "\n",
    "# Time to hit ground: t = sqrt(2h/g)\n",
    "t_stop = np.sqrt(2.0 * h_true / g_true)\n",
    "t_final = 0.7 * t_stop  # Stop before hitting ground\n",
    "t_span = np.linspace(0.0, t_final, 61)\n",
    "\n",
    "# Generate clean data\n",
    "height, velocity = ball_states(t_span, g_true, h_true)\n",
    "\n",
    "# Add measurement noise\n",
    "noise_std = 0.1\n",
    "height_noisy = height + np.random.normal(0, noise_std, len(t_span))\n",
    "velocity_noisy = velocity + np.random.normal(0, noise_std, len(t_span))\n",
    "\n",
    "# Format for Chronopt: [time, height, velocity]\n",
    "data = np.column_stack((t_span, height_noisy, velocity_noisy))\n",
    "\n",
    "print(f\"Generated {len(t_span)} observations\")\n",
    "print(f\"Time span: [0, {t_final:.3f}] seconds\")\n",
    "print(f\"Noise level: σ = {noise_std}\")\n",
    "print(\"\\nTrue parameters:\")\n",
    "print(f\"  g = {g_true} m/s²\")\n",
    "print(f\"  h = {h_true} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Height\n",
    "axes[0].plot(t_span, height, \"--\", label=\"True\", linewidth=2, alpha=0.7)\n",
    "axes[0].plot(t_span, height_noisy, \"o\", label=\"Observed\", alpha=0.6)\n",
    "axes[0].set_xlabel(\"Time (s)\")\n",
    "axes[0].set_ylabel(\"Height (m)\")\n",
    "axes[0].set_title(\"Ball Height\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Velocity\n",
    "axes[1].plot(t_span, velocity, \"--\", label=\"True\", linewidth=2, alpha=0.7)\n",
    "axes[1].plot(t_span, velocity_noisy, \"o\", label=\"Observed\", alpha=0.6)\n",
    "axes[1].set_xlabel(\"Time (s)\")\n",
    "axes[1].set_ylabel(\"Velocity (m/s)\")\n",
    "axes[1].set_title(\"Ball Velocity\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the ODE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DiffSL model for falling ball\n",
    "dsl_model = \"\"\"\n",
    "in = [g, h]\n",
    "g { 1 } h { 1 }\n",
    "u_i {x = h, v = 0}\n",
    "F_i {v, -g}\n",
    "stop {x}\n",
    "\"\"\"\n",
    "\n",
    "print(\"DiffSL Model:\")\n",
    "print(dsl_model)\n",
    "print(\"\\nExplanation:\")\n",
    "print(\"  x = height, v = velocity\")\n",
    "print(\"  dx/dt = v (velocity determines height change)\")\n",
    "print(\"  dv/dt = -g (gravity accelerates downward)\")\n",
    "print(\"  stop {x} (terminate when height reaches zero)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Optimization\n",
    "\n",
    "First, find the maximum a posteriori (MAP) estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build problem\n",
    "builder = (\n",
    "    chron.DiffsolBuilder()\n",
    "    .with_diffsl(dsl_model)\n",
    "    .with_data(data)\n",
    "    .with_parameter(\"g\", 5.0)  # Initial guess\n",
    "    .with_parameter(\"h\", 5.0)  # Initial guess\n",
    "    .with_cost(chron.RMSE(2.0))  # 2 observables (height + velocity)\n",
    ")\n",
    "\n",
    "problem = builder.build()\n",
    "\n",
    "# Optimize\n",
    "optimizer = chron.Adam().with_step_size(0.05).with_max_iter(1500)\n",
    "opt_result = optimizer.run(problem, [5.0, 5.0])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OPTIMIZATION RESULTS (MAP Estimate)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Success: {opt_result.success}\")\n",
    "print(\"\\nFitted parameters:\")\n",
    "print(f\"  g = {opt_result.x[0]:.4f} m/s²  (true: {g_true})\")\n",
    "print(f\"  h = {opt_result.x[1]:.4f} m     (true: {h_true})\")\n",
    "print(f\"\\nCost: {opt_result.value:.6f}\")\n",
    "print(f\"Iterations: {opt_result.iterations}\")\n",
    "\n",
    "g_map, h_map = opt_result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: MCMC Sampling\n",
    "\n",
    "Now explore the full posterior distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild problem with GaussianNLL (required for sampling)\n",
    "builder_sampling = (\n",
    "    chron.DiffsolBuilder()\n",
    "    .with_diffsl(dsl_model)\n",
    "    .with_data(data)\n",
    "    .with_parameter(\"g\", g_map)  # Start from MAP\n",
    "    .with_parameter(\"h\", h_map)\n",
    "    .with_parallel(True)\n",
    "    .with_cost(chron.GaussianNLL(variance=noise_std**2))\n",
    ")\n",
    "\n",
    "problem_sampling = builder_sampling.build()\n",
    "\n",
    "# Setup MCMC sampler\n",
    "sampler = (\n",
    "    chron.MetropolisHastings()\n",
    "    .with_num_chains(100)\n",
    "    .with_iterations(1000)\n",
    "    .with_step_size(0.25)\n",
    "    .with_parallel(True)\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MCMC SAMPLING\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Chains: 100\")\n",
    "print(\"Iterations per chain: 1000\")\n",
    "print(\"Total samples: 100,000\")\n",
    "print(f\"\\nStarting from MAP estimate: g = {g_map:.4f}, h = {h_map:.4f}\")\n",
    "print(\"\\nRunning MCMC... (this may take a minute)\")\n",
    "\n",
    "# Run sampling\n",
    "mcmc_result = sampler.run(problem_sampling, [g_map, h_map])\n",
    "\n",
    "print(\"\\nSampling complete!\")\n",
    "print(f\"Samples shape: {mcmc_result.samples.shape}\")\n",
    "print(f\"Acceptance rate: {mcmc_result.acceptance_rate:.3f}\")\n",
    "print(\"Target acceptance: 0.20 - 0.40\")\n",
    "\n",
    "if mcmc_result.acceptance_rate < 0.15 or mcmc_result.acceptance_rate > 0.50:\n",
    "    print(\"⚠️  Warning: Acceptance rate is outside optimal range\")\n",
    "    print(\"   Consider adjusting step_size\")\n",
    "else:\n",
    "    print(\"✓ Acceptance rate looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze MCMC Results\n",
    "\n",
    "### Parameter Traces\n",
    "\n",
    "Trace plots show how parameters evolved during sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot traces\n",
    "fig, axes = plot_parameter_traces(\n",
    "    mcmc_result.samples, param_names=[\"g (m/s²)\", \"h (m)\"], true_values=[g_true, h_true]\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nWhat to look for in traces:\")\n",
    "print(\"  ✓ Good mixing (wiggly, no trends)\")\n",
    "print(\"  ✓ Stationary (mean stays constant)\")\n",
    "print(\"  ✓ No long excursions\")\n",
    "print(\"  ✓ Rapid exploration of parameter space\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Distributions\n",
    "\n",
    "Histograms show the posterior distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions\n",
    "fig, axes = plot_parameter_distributions(\n",
    "    mcmc_result.samples, param_names=[\"g (m/s²)\", \"h (m)\"], true_values=[g_true, h_true]\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burn-in: discard first 20% of samples\n",
    "burn_in = int(0.2 * len(mcmc_result.samples))\n",
    "samples_burned = mcmc_result.samples[burn_in:]\n",
    "\n",
    "# Calculate statistics\n",
    "g_samples = samples_burned[:, 0]\n",
    "h_samples = samples_burned[:, 1]\n",
    "\n",
    "# Means and standard deviations\n",
    "g_mean = np.mean(g_samples)\n",
    "g_std = np.std(g_samples)\n",
    "h_mean = np.mean(h_samples)\n",
    "h_std = np.std(h_samples)\n",
    "\n",
    "# 95% credible intervals\n",
    "g_ci = np.percentile(g_samples, [2.5, 97.5])\n",
    "h_ci = np.percentile(h_samples, [2.5, 97.5])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"POSTERIOR STATISTICS (after burn-in)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Samples used: {len(samples_burned):,}\")\n",
    "print(\"\\nGravitational acceleration (g):\")\n",
    "print(f\"  True value:  {g_true:.4f} m/s²\")\n",
    "print(f\"  MAP:         {g_map:.4f} m/s²\")\n",
    "print(f\"  Posterior:   {g_mean:.4f} ± {g_std:.4f} m/s²\")\n",
    "print(f\"  95% CI:      [{g_ci[0]:.4f}, {g_ci[1]:.4f}]\")\n",
    "print(\"\\nInitial height (h):\")\n",
    "print(f\"  True value:  {h_true:.4f} m\")\n",
    "print(f\"  MAP:         {h_map:.4f} m\")\n",
    "print(f\"  Posterior:   {h_mean:.4f} ± {h_std:.4f} m\")\n",
    "print(f\"  95% CI:      [{h_ci[0]:.4f}, {h_ci[1]:.4f}]\")\n",
    "\n",
    "# Check if true values are in credible intervals\n",
    "g_in_ci = g_ci[0] <= g_true <= g_ci[1]\n",
    "h_in_ci = h_ci[0] <= h_true <= h_ci[1]\n",
    "\n",
    "print(\"\\nTrue values in 95% CI:\")\n",
    "print(f\"  g: {'✓' if g_in_ci else '✗'}\")\n",
    "print(f\"  h: {'✓' if h_in_ci else '✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of joint distribution\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Hexbin plot for large sample sizes\n",
    "hb = ax.hexbin(g_samples, h_samples, gridsize=50, cmap=\"Blues\", mincnt=1)\n",
    "ax.plot(g_true, h_true, \"r*\", markersize=20, label=\"True values\", zorder=5)\n",
    "ax.plot(g_map, h_map, \"go\", markersize=12, label=\"MAP estimate\", zorder=5)\n",
    "ax.plot(g_mean, h_mean, \"mo\", markersize=12, label=\"Posterior mean\", zorder=5)\n",
    "\n",
    "ax.set_xlabel(\"g (m/s²)\", fontsize=12)\n",
    "ax.set_ylabel(\"h (m)\", fontsize=12)\n",
    "ax.set_title(\"Joint Posterior Distribution\", fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.colorbar(hb, ax=ax, label=\"Sample density\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = np.corrcoef(g_samples, h_samples)[0, 1]\n",
    "print(f\"\\nParameter correlation: {correlation:.4f}\")\n",
    "\n",
    "if abs(correlation) > 0.7:\n",
    "    print(\"  High correlation - parameters are not independently identifiable\")\n",
    "elif abs(correlation) > 0.3:\n",
    "    print(\"  Moderate correlation\")\n",
    "else:\n",
    "    print(\"  Low correlation - parameters are nearly independent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Predictive Distribution\n",
    "\n",
    "Use samples to make probabilistic predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take random subset of samples for predictions\n",
    "n_pred_samples = 200\n",
    "sample_indices = np.random.choice(len(samples_burned), n_pred_samples, replace=False)\n",
    "\n",
    "# Generate predictions for each sample\n",
    "predictions_height = []\n",
    "predictions_velocity = []\n",
    "\n",
    "for idx in sample_indices:\n",
    "    g_sample, h_sample = samples_burned[idx]\n",
    "    h_pred, v_pred = ball_states(t_span, g_sample, h_sample)\n",
    "    predictions_height.append(h_pred)\n",
    "    predictions_velocity.append(v_pred)\n",
    "\n",
    "predictions_height = np.array(predictions_height)\n",
    "predictions_velocity = np.array(predictions_velocity)\n",
    "\n",
    "# Calculate percentiles\n",
    "h_median = np.median(predictions_height, axis=0)\n",
    "h_lower = np.percentile(predictions_height, 2.5, axis=0)\n",
    "h_upper = np.percentile(predictions_height, 97.5, axis=0)\n",
    "\n",
    "v_median = np.median(predictions_velocity, axis=0)\n",
    "v_lower = np.percentile(predictions_velocity, 2.5, axis=0)\n",
    "v_upper = np.percentile(predictions_velocity, 97.5, axis=0)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Height\n",
    "axes[0].fill_between(t_span, h_lower, h_upper, alpha=0.3, label=\"95% CI\")\n",
    "axes[0].plot(t_span, h_median, \"-\", linewidth=2, label=\"Median prediction\")\n",
    "axes[0].plot(t_span, height, \"--\", linewidth=2, label=\"True\", alpha=0.7)\n",
    "axes[0].plot(t_span, height_noisy, \"o\", label=\"Observed\", alpha=0.4, markersize=4)\n",
    "axes[0].set_xlabel(\"Time (s)\")\n",
    "axes[0].set_ylabel(\"Height (m)\")\n",
    "axes[0].set_title(\"Posterior Predictive: Height\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Velocity\n",
    "axes[1].fill_between(t_span, v_lower, v_upper, alpha=0.3, label=\"95% CI\")\n",
    "axes[1].plot(t_span, v_median, \"-\", linewidth=2, label=\"Median prediction\")\n",
    "axes[1].plot(t_span, velocity, \"--\", linewidth=2, label=\"True\", alpha=0.7)\n",
    "axes[1].plot(t_span, velocity_noisy, \"o\", label=\"Observed\", alpha=0.4, markersize=4)\n",
    "axes[1].set_xlabel(\"Time (s)\")\n",
    "axes[1].set_ylabel(\"Velocity (m/s)\")\n",
    "axes[1].set_title(\"Posterior Predictive: Velocity\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The shaded region shows the 95% credible interval for predictions\")\n",
    "print(\"This accounts for both parameter uncertainty and observation noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Optimization** gives point estimates; **MCMC** quantifies uncertainty\n",
    "2. **GaussianNLL** cost metric is required for sampling\n",
    "3. **Acceptance rate** should be 20-40% for efficient exploration\n",
    "4. **Burn-in** period discards initial non-stationary samples\n",
    "5. **Credible intervals** provide uncertainty bounds\n",
    "6. **Posterior predictive** distributions account for parameter uncertainty\n",
    "\n",
    "## MCMC Diagnostics Checklist\n",
    "\n",
    "✓ Acceptance rate in [0.2, 0.4]  \n",
    "✓ Trace plots show good mixing  \n",
    "✓ No trends in traces  \n",
    "✓ Distributions look reasonable  \n",
    "✓ True values in credible intervals  \n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- [Tutorial 4: Model Comparison](04_model_comparison.ipynb) - Use nested sampling for Bayes factors\n",
    "- [Choosing a Sampler](../../guides/choosing-sampler.md) - MCMC vs Nested Sampling\n",
    "- [API Reference: Samplers](../../api-reference/python/samplers.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Step Size**: Try different `step_size` values (0.1, 0.5, 1.0) and observe acceptance rates\n",
    "\n",
    "2. **More Data**: Increase the number of observations and see how uncertainty decreases\n",
    "\n",
    "3. **More Noise**: Increase `noise_std` to 0.5 and observe wider credible intervals\n",
    "\n",
    "4. **Longer Chains**: Run with 10,000 iterations per chain for better convergence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
